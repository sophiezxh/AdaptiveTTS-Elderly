{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for MEADTTS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "PROJECT_PATH = os.path.join('/', *os.getcwd().split(os.sep)[:-1])\n",
    "\n",
    "# MEADTTS data path, e.g. data/MEADTTS\n",
    "MEADTTS_PATH = f'{PROJECT_PATH}/data/MEADTTS'\n",
    "# MEADTTS audio data path, e.g. data/MEADTTS/raw\n",
    "MEADTTS_RAW_PATH = f'{MEADTTS_PATH}/raw'\n",
    "# MEADTTS transcript data path, e.g. data/MEADTTS/transcript\n",
    "MEADTTS_TRANSCRIPT_PATH = f'{MEADTTS_PATH}/mead_transcript'\n",
    "\n",
    "# Copy and split MEADTTS raw data by speaker folder for MFA, e.g. data/MEAD_MFA\n",
    "MEADTTS_MFA = f'{PROJECT_PATH}/data/MEADTTS_MFA'\n",
    "\n",
    "# preprocessed MFA data, e.g. data/MEADTTS_MFA_preprocessed\n",
    "MEADTTS_MFA_PREPRO = f'{PROJECT_PATH}/data/MEADTTS_MFA_preprocessed'\n",
    "\n",
    "# filelist path for load MEADTTS data for training, validation and testing, e.g. EMITTS/filelist/MEADTTS\n",
    "FILELIST_PATH = f'{PROJECT_PATH}/EMITTS/filelist/MEADTTS'\n",
    "os.makedirs(FILELIST_PATH, exist_ok=True)\n",
    "\n",
    "# EMO_FEATURE_SAVE_PATH is the path to save the extracted emotion features, e.g. EPAlign/mmefeature/MEADTTS\n",
    "EMO_FEATURE_SAVE_PATH = f\"{PROJECT_PATH}/EPAlign/mmefeature/MEADTTS\"\n",
    "\n",
    "# find all the wav files\n",
    "def find_file(path, suffix):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name.endswith(suffix):\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "def load_filelist(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        filelist = [line.strip().split(split) for line in f]\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = find_file(MEADTTS_RAW_PATH, '.wav')\n",
    "wav_dict = {}\n",
    "for wav_file in wav_files:\n",
    "    wav_dict[wav_file.split('/')[-1][:-4]] = wav_file\n",
    "\n",
    "assert len(wav_dict) == 31_055\n",
    "\n",
    "df_total = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "for file in find_file(MEADTTS_TRANSCRIPT_PATH, '.txt'):\n",
    "    filename = file.split('/')[-1][:-4]\n",
    "    text = open(file, 'r', encoding='utf-8').read().strip()\n",
    "    emotion_tag = f'{filename.split(\"_\")[1]}_{filename.split(\"_\")[2]}_{filename.split(\"_\")[3]}'\n",
    "    df_total = pd.concat([df_total, pd.DataFrame({'filename': [filename], 'text': [text], 'emotiontag': [emotion_tag]})], ignore_index=True)\n",
    "\n",
    "emotion_tags_set = set(df_total['emotiontag'])\n",
    "emotion_tags = [emotion_tag for emotion_tag in emotion_tags_set]\n",
    "train_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "val_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "test_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "\n",
    "for emotion_tag in emotion_tags:\n",
    "    df_e = df_total[df_total['emotiontag'] == emotion_tag].to_numpy()\n",
    "    # split the data into train, val, test with 80%, 10%, 10%\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(df_e)\n",
    "    df_tr = pd.DataFrame(df_e[:int(len(df_e)*0.8)], columns=['filename', 'text', 'emotiontag'])\n",
    "    df_va = pd.DataFrame(df_e[int(len(df_e)*0.8):int(len(df_e)*0.9)], columns=['filename', 'text', 'emotiontag'])\n",
    "    df_te = pd.DataFrame(df_e[int(len(df_e)*0.9):], columns=['filename', 'text', 'emotiontag'])\n",
    "    train_df = pd.concat([train_df, df_tr])\n",
    "    val_df = pd.concat([val_df, df_va])\n",
    "    test_df = pd.concat([test_df, df_te])\n",
    "\n",
    "assert len(train_df) == 24_836\n",
    "assert len(val_df) == 3_103\n",
    "assert len(test_df) == 3_116\n",
    "\n",
    "# save train, val, test filelist\n",
    "train_val_test = [\"train\", \"val\", \"test\"]\n",
    "dfs = [train_df, val_df, test_df]\n",
    "for i, df in enumerate(dfs):\n",
    "    new_filelist = f'{FILELIST_PATH}/MEADTTS_audio_sid_text_efeature_{train_val_test[i]}_filelist.txt'\n",
    "    with open(new_filelist, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            wav_path = wav_dict[row['filename']]\n",
    "            sid = int(row['filename'].split('_')[0][1:]) if row['filename'].split('_')[0][0] == 'W' else int(row['filename'].split('_')[0][1:]) + 40\n",
    "            text = row['text']\n",
    "            mmefeature_path = f'{EMO_FEATURE_SAVE_PATH}/{row['emotiontag'].lower()}.pt'\n",
    "            f.write(f'{wav_path}|{str(sid)}|{text}|{mmefeature_path}\\n')\n",
    "    print(f'Saved {new_filelist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text for VITS Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'{PROJECT_PATH}/EMITTS/VITS')\n",
    "import utils.text_utils as text\n",
    "\n",
    "# test_text = test_df['text'].to_list()\n",
    "# train_text = train_df['text'].to_list()\n",
    "\n",
    "# t = text._clean_text(test_text, [\"english_cleaners2\"])\n",
    "\n",
    "# save train, val, test clean text filelist\n",
    "train_val_test = [\"train\", \"val\", \"test\"]\n",
    "dfs = [train_df, val_df, test_df]\n",
    "for i, df in enumerate(dfs):\n",
    "    new_filelist = f'{FILELIST_PATH}/MEADTTS_audio_sid_text_efeature_{train_val_test[i]}_filelist.txt.cleaned'\n",
    "    clean_texts = text._clean_text(df['text'].to_list(), [\"english_cleaners2\"])\n",
    "    with open(new_filelist, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            wav_path = wav_dict[row['filename']]\n",
    "            sid = int(row['filename'].split('_')[0][1:]) if row['filename'].split('_')[0][0] == 'W' else int(row['filename'].split('_')[0][1:]) + 40\n",
    "            clean_text = clean_texts[index]\n",
    "            mmefeature_path = f'{EMO_FEATURE_SAVE_PATH}/{row['emotiontag'].lower()}.pt'\n",
    "            f.write(f'{wav_path}|{str(sid)}|{clean_text}|{mmefeature_path}\\n')\n",
    "    print(f'Saved {new_filelist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text for FastSpeech2 Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/en/latest/) (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
    "\n",
    "The following steps are used to align the utterances and the phoneme sequences refer to the [mfa-ljspeech.ipynb](https://gist.github.com/12264d15afad861cb897f7a20a01762e.git):\n",
    "\n",
    "1. install using [mamba](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html#)\n",
    "    ```bash\n",
    "    # create and install\n",
    "    mamba create -n aligner -c conda-forge montreal-forced-aligner\n",
    "\n",
    "    # install \n",
    "    mamba install -c conda-forge montreal-forced-aligner\n",
    "    ```\n",
    "\n",
    "2. download and modify the pre-trained model and the lexicon (current working directory is the root of the project)\n",
    "    ```bash\n",
    "    mamba activate aligner\n",
    "    wget -O ./data/english.zip https://github.com/MontrealCorpusTools/mfa-models/raw/main/acoustic/english.zip\n",
    "    wget -O ./data/librispeech-lexicon.txt http://www.openslr.org/resources/11/librispeech-lexicon.txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/pull/480\n",
    "import re\n",
    "lexicon = open(f\"{PROJECT_PATH}/data/librispeech-lexicon.txt\").readlines()\n",
    "sp = re.compile(r\"\\s+\")\n",
    "with open(f\"{PROJECT_PATH}/data/modified_lexicon.txt\", \"w\") as f:\n",
    "    for line in lexicon:\n",
    "        word, *phonemes = sp.split(line.strip())\n",
    "        phonemes = \" \".join(phonemes)\n",
    "        f.write(f\"{word}\\t{phonemes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. prepare MEADTTS_SP data (split the data with speaker id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MEADTTS_MFA, exist_ok=True)\n",
    "\n",
    "speakers = [speaker for speaker in set(df_total['filename'].apply(lambda x: x.split('_')[0]))]\n",
    "for speaker in speakers:\n",
    "    os.system(f'mkdir -p {MEADTTS_MFA}/{speaker}')\n",
    "\n",
    "wav_paths = find_file(MEADTTS_RAW_PATH, '.wav')\n",
    "for wav_path in wav_paths:\n",
    "    speaker = wav_path.split('/')[-1].split('_')[0]\n",
    "    os.system(f'cp {wav_path} {MEADTTS_MFA}/{speaker}')\n",
    "print(f'Copied all .wav files from {MEADTTS_RAW_PATH} to {MEADTTS_MFA} by speaker folder')\n",
    "\n",
    "for file in find_file(MEADTTS_TRANSCRIPT_PATH, '.txt'):\n",
    "    # print(file)\n",
    "    filename = file.split('/')[-1][:-4]\n",
    "    os.system(f'cp {file} {MEADTTS_MFA}/{filename.split(\"_\")[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. using MFA to align the utterances and the phoneme sequences (current working directory is the root of the project)\n",
    "    ```bash\n",
    "    mfa align -t ./data/mfa_temp -j 47 ./data/MEADTTS_MFA ./data/modified_lexicon.txt ./data/english.zip ./data/MEADTTS_MFA\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for speaker in speakers:\n",
    "    os.system(f'mv {MEADTTS_MFA}/{speaker}/* {MEADTTS_MFA}')\n",
    "    os.system(f'rm -r {MEADTTS_MFA}/{speaker}')\n",
    "    print(f'Moved all files from {MEADTTS_MFA}/{speaker} to {MEADTTS_MFA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from EMITTS.FastSpeech2.config.config import TrainConfig\n",
    "sys.path.append(f'{PROJECT_PATH}/EMITTS/FastSpeech2')\n",
    "from EMITTS.FastSpeech2.src.preprocess.preprocess import Preprocessor\n",
    "cfg = TrainConfig()\n",
    "\n",
    "cfg.raw_data_path = MEADTTS_MFA\n",
    "cfg.train_ids_path = f'{FILELIST_PATH}/MEADTTS_audio_sid_text_efeature_train_filelist.txt'\n",
    "cfg.val_ids_path = f'{FILELIST_PATH}/MEADTTS_audio_sid_text_efeature_val_filelist.txt'\n",
    "cfg.test_ids_path = f'{FILELIST_PATH}/MEADTTS_audio_sid_text_efeature_test_filelist.txt'\n",
    "cfg.preprocessed_data_path = MEADTTS_MFA_PREPRO\n",
    "\n",
    "preprocessor = Preprocessor(cfg)\n",
    "preprocessor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMTTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
